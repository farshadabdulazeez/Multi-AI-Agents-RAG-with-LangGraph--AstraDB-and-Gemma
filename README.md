# ğŸ¤– Multi-Agent RAG System with LangGraph, AstraDB, and Gemma

This project implements a **Multi-Agent Retrieval-Augmented Generation (RAG) system** using:

- ğŸ§  **LangGraph** â€“ to orchestrate intelligent multi-agent workflows  
- ğŸŒ **Wikipedia Search** â€“ for public knowledge retrieval  
- ğŸ” **AstraDB** â€“ as a scalable vector store for custom document embedding retrieval  
- âœ¨ **Gemma** â€“ for enhanced natural language understanding and generation  

The system intelligently routes user queries between Wikipedia and a custom vector store using LangGraphâ€™s agent-based architecture. This hybrid setup ensures accurate, relevant, and context-aware responses.

---

## ğŸš€ Features

- ğŸ§© **Multi-Agent Design**: Modular agents for query rephrasing, Wikipedia search, vector DB search, and response generation.
- ğŸ”„ **Routing Logic**: Dynamically decides which path to take based on query type.
- ğŸ“š **Context-Aware Retrieval**: Integrates both live Wikipedia data and your custom knowledge base.
- ğŸ—ƒï¸ **AstraDB Integration**: Uses Cassandra + vector embeddings for scalable retrieval.
- ğŸ—¨ï¸ **Gemma LLM**: Powers the reasoning and generation of final responses.
- ğŸ” **Prompt Engineering**: Utilizes in-context prompting for better agent performance.

---

## ğŸ› ï¸ Tech Stack

- `LangGraph`
- `Gemma` (via HuggingFace / LangChain)
- `AstraDB` (Vector Store)
- `Wikipedia API`
- `LangChain`
- `Python 3.10+`

---

## âš™ï¸ How It Works

1. **User inputs a question**
2. **Router agent** decides:
   - â†’ Search Wikipedia
   - â†’ Search AstraDB
3. **Relevant documents** are retrieved and passed to the generation agent
4. **Gemma LLM** composes the final response using retrieved knowledge

---

